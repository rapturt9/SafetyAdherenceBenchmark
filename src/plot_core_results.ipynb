{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety Adherence Benchmark - Core Analysis\n",
    "\n",
    "This notebook generates visualizations to answer our core research questions:\n",
    "\n",
    "- **RQ1**: Principle Influence & Prioritization\n",
    "- **RQ2**: Compliant Solution Finding & Efficiency Cost\n",
    "- **RQ3**: Model Variation in Principle Adherence\n",
    "- **RQ4**: Impact of Principle Type\n",
    "\n",
    "Our goal is to explore how language models balance task completion with safety principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Set style parameters\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('colorblind')\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 150\n",
    "\n",
    "# Configure paths\n",
    "data_path = os.path.join('..', 'src', 'benchmark_results_all.csv')\n",
    "output_dir = os.path.join('..', 'results', 'core_plots')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Helper function to ensure percentages are displayed correctly\n",
    "def format_percent_axis(ax):\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks(np.arange(0, 1.1, 0.2))\n",
    "    ax.set_yticklabels([f'{int(x*100)}%' for x in ax.get_yticks()])\n",
    "\n",
    "# Define key scenarios for each research question\n",
    "# RQ1: Focus on clear unavoidable conflict scenarios\n",
    "RQ1_SCENARIOS = ['P1-S1', 'P2-S1', 'P3-S1']  # One clear example per principle\n",
    "\n",
    "# RQ2: Focus on avoidable conflict scenarios\n",
    "RQ2_SCENARIOS = ['P1-S2', 'P2-S2', 'P3-S2']  # Key avoidable conflict scenarios\n",
    "\n",
    "# RQ3: Use all unavoidable scenarios for model comparison\n",
    "RQ3_SCENARIOS = ['P1-S1', 'P1-S3', 'P2-S1', 'P2-S4', 'P3-S1', 'P3-S3']  # Multiple scenarios per principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the data\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Loaded {len(df)} rows of data\")\n",
    "\n",
    "# Create scenario classification\n",
    "conflict_avoidable = {\n",
    "    'P1': ['P1-S1', 'P1-S2'],\n",
    "    'P2': ['P2-S2', 'P2-S3'],\n",
    "    'P3': ['P3-S2', 'P3-S4']\n",
    "}\n",
    "\n",
    "# Add conflict type column to the dataframe\n",
    "df['conflict_type'] = df.apply(\n",
    "    lambda row: 'Conflict-Avoidable' if row['scenario_id'] in conflict_avoidable.get(row['principle_id'], []) \n",
    "    else 'Conflict-Unavoidable', axis=1\n",
    ")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nUnique models:\")\n",
    "print(df['model'].unique())\n",
    "\n",
    "print(\"\\nUnique principles:\")\n",
    "print(df['principle_id'].unique())\n",
    "\n",
    "print(\"\\nNumber of scenarios per principle:\")\n",
    "print(df.groupby(['principle_id', 'scenario_id']).size().unstack().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1: Principle Influence & Prioritization\n",
    "\n",
    "**Research Question**: Does the explicitly stated Core Principle actually change the agent's behavior, especially in conflict?\n",
    "\n",
    "To answer this, we'll analyze the unavoidable conflict scenarios where agents must choose between adhering to the principle and completing the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Impact of Principles in Unavoidable Conflict Scenarios\n",
    "\n",
    "# Filter for all unavoidable conflict scenarios\n",
    "unavoidable_df = df[df['conflict_type'] == 'Conflict-Unavoidable'].copy()\n",
    "\n",
    "# Group by principle, scenario, and control type\n",
    "grouped_rq1 = unavoidable_df.groupby(['principle_id', 'scenario_id', 'control_type'])\n",
    "summary_rq1 = grouped_rq1.agg({\n",
    "    'principle_adhered': ['mean', 'std'], \n",
    "    'task_success': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the multi-index columns\n",
    "summary_rq1.columns = ['_'.join(col).strip('_') for col in summary_rq1.columns.values]\n",
    "\n",
    "# Create a figure with two side-by-side plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Plot A: Principle Adherence Rates\n",
    "sns.barplot(\n",
    "    data=summary_rq1, \n",
    "    x='scenario_id_', \n",
    "    y='principle_adhered_mean', \n",
    "    hue='control_type_',\n",
    "    ax=axes[0],\n",
    "    palette=['lightgrey', 'darkblue']\n",
    ")\n",
    "\n",
    "# Add error bars if you have multiple trials\n",
    "axes[0].errorbar(\n",
    "    x=np.arange(len(summary_rq1)), \n",
    "    y=summary_rq1['principle_adhered_mean'],\n",
    "    yerr=summary_rq1['principle_adhered_std'],\n",
    "    fmt='none', \n",
    "    color='black', \n",
    "    capsize=5\n",
    ")\n",
    "\n",
    "axes[0].set_title('Principle Adherence Rate (PAR) in Unavoidable Conflicts', fontsize=14)\n",
    "axes[0].set_xlabel('Scenario')\n",
    "format_percent_axis(axes[0])\n",
    "axes[0].legend(title='Control Type')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Plot B: Task Success Rates\n",
    "sns.barplot(\n",
    "    data=summary_rq1, \n",
    "    x='scenario_id_', \n",
    "    y='task_success_mean', \n",
    "    hue='control_type_',\n",
    "    ax=axes[1],\n",
    "    palette=['lightgrey', 'darkblue']\n",
    ")\n",
    "\n",
    "# Add error bars\n",
    "axes[1].errorbar(\n",
    "    x=np.arange(len(summary_rq1)), \n",
    "    y=summary_rq1['task_success_mean'],\n",
    "    yerr=summary_rq1['task_success_std'],\n",
    "    fmt='none', \n",
    "    color='black', \n",
    "    capsize=5\n",
    ")\n",
    "\n",
    "axes[1].set_title('Task Success Rate (TSR) in Unavoidable Conflicts', fontsize=14)\n",
    "axes[1].set_xlabel('Scenario')\n",
    "format_percent_axis(axes[1])\n",
    "axes[1].legend(title='Control Type')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.suptitle('Core Principle Significantly Alters Behavior in Unavoidable Conflict Scenarios', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'rq1_principle_influence.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualization for RQ1: Small multiples showing key models\n",
    "\n",
    "# Select a few contrasting models\n",
    "contrast_models = df['model'].unique()  # Taking first 3 models as an example\n",
    "\n",
    "# Filter data for selected models and unavoidable conflict scenarios using hardcoded list\n",
    "rq1_models_df = df[(df['scenario_id'].isin(RQ1_SCENARIOS)) & \n",
    "                   (df['model'].isin(contrast_models))].copy()\n",
    "\n",
    "# Create a new column for the metric we want to display based on control_type\n",
    "rq1_models_df['display_metric'] = rq1_models_df.apply(\n",
    "    lambda row: row['principle_adhered'] if row['control_type'] == 'Principle_ON' else row['task_success'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create a facet grid\n",
    "g = sns.FacetGrid(\n",
    "    rq1_models_df, \n",
    "    col='model',\n",
    "    row='principle_id',\n",
    "    height=4, \n",
    "    aspect=1.2,\n",
    "    sharex=True,\n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "# Map barplot showing the appropriate metric for each control type\n",
    "g.map_dataframe(\n",
    "    sns.barplot,\n",
    "    x='control_type',\n",
    "    y='display_metric',\n",
    "    palette=['lightgrey', 'darkblue'],\n",
    "    errorbar=None\n",
    ")\n",
    "\n",
    "# Add titles and annotations\n",
    "g.set_axis_labels(\"Control Type\", \"Rate\")\n",
    "g.set_titles(col_template=\"{col_name}\", row_template=\"{row_name}\")\n",
    "\n",
    "# Add a more descriptive legend\n",
    "for ax in g.axes.flat:\n",
    "    format_percent_axis(ax)\n",
    "    # Add annotations to clarify what each bar represents\n",
    "    if ax is g.axes.flat[-1]:  # Add this to only one subplot\n",
    "        ax.text(0, -0.2, \"Task Success Rate\", color=\"gray\", ha=\"center\", transform=ax.get_xticklabels()[0].get_transform())\n",
    "        ax.text(1, -0.2, \"Principle Adherence Rate\", color=\"darkblue\", ha=\"center\", transform=ax.get_xticklabels()[1].get_transform())\n",
    "\n",
    "g.fig.suptitle('Trade-off: Task Success (Principle OFF) vs. Principle Adherence (Principle ON)', fontsize=16)\n",
    "plt.subplots_adjust(top=0.9, bottom=0.15)\n",
    "plt.savefig(os.path.join(output_dir, 'rq1_model_comparison.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2: Compliant Solution Finding & Efficiency Cost\n",
    "\n",
    "**Research Question**: If a safe, compliant path exists, can agents find it, and at what cost?\n",
    "\n",
    "Here we examine the avoidable conflict scenarios where agents should be able to both follow the principle and complete the task, though possibly with increased effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2A: Success & Adherence in Avoidable Conflict Scenarios\n",
    "\n",
    "# Filter for all avoidable conflict scenarios\n",
    "rq2_df = df[(df['conflict_type'] == 'Conflict-Avoidable') & (df['scenario_id'].isin(RQ2_SCENARIOS))].copy()\n",
    "\n",
    "# Filter for just the Principle_ON cases\n",
    "principle_on_df = rq2_df[rq2_df['control_type'] == 'Principle_ON'].copy()\n",
    "\n",
    "# Group and calculate means\n",
    "grouped_rq2a = principle_on_df.groupby(['principle_id', 'scenario_id'])\n",
    "summary_rq2a = grouped_rq2a.agg({\n",
    "    'principle_adhered': ['mean', 'std'], \n",
    "    'task_success': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-index\n",
    "summary_rq2a.columns = ['_'.join(col).strip('_') for col in summary_rq2a.columns.values]\n",
    "\n",
    "# Reshape for grouped bar plot (PAR and TSR side-by-side)\n",
    "plot_data = pd.melt(\n",
    "    summary_rq2a,\n",
    "    id_vars=['principle_id_', 'scenario_id_'],\n",
    "    value_vars=['principle_adhered_mean', 'task_success_mean'],\n",
    "    var_name='metric',\n",
    "    value_name='rate'\n",
    ")\n",
    "\n",
    "# Map column names to better labels\n",
    "plot_data['metric'] = plot_data['metric'].map({\n",
    "    'principle_adhered_mean': 'Principle Adherence',\n",
    "    'task_success_mean': 'Task Success'\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(\n",
    "    data=plot_data,\n",
    "    x='scenario_id_',\n",
    "    y='rate',\n",
    "    hue='metric',\n",
    "    palette=['darkblue', 'darkorange']\n",
    ")\n",
    "\n",
    "# Add error bars - this would need adjusted for the melted structure\n",
    "# Omitted for clarity in this example\n",
    "\n",
    "plt.title('Principle Adherence and Task Success in Conflict-Avoidable Scenarios (Principle ON)', fontsize=14)\n",
    "plt.xlabel('Scenario')\n",
    "plt.ylabel('Rate')\n",
    "format_percent_axis(ax)\n",
    "plt.legend(title='')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'rq2a_adherence_success.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2B: Efficiency Cost in Avoidable Conflict Scenarios\n",
    "\n",
    "# Group by principle, scenario, and control type to show efficiency costs\n",
    "grouped_rq2b = rq2_df.groupby(['principle_id', 'scenario_id', 'control_type'])\n",
    "summary_rq2b = grouped_rq2b.agg({\n",
    "    'steps_taken': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-index\n",
    "summary_rq2b.columns = ['_'.join(col).strip('_') for col in summary_rq2b.columns.values]\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(\n",
    "    data=summary_rq2b,\n",
    "    x='scenario_id_',\n",
    "    y='steps_taken_mean',\n",
    "    hue='control_type_',\n",
    "    palette=['lightgrey', 'darkblue']\n",
    ")\n",
    "\n",
    "# Add error bars\n",
    "ax.errorbar(\n",
    "    x=np.arange(len(summary_rq2b)), \n",
    "    y=summary_rq2b['steps_taken_mean'],\n",
    "    yerr=summary_rq2b['steps_taken_std'],\n",
    "    fmt='none', \n",
    "    color='black', \n",
    "    capsize=5\n",
    ")\n",
    "\n",
    "plt.title('Cost of Compliance: Steps Taken in Conflict-Avoidable Scenarios', fontsize=14)\n",
    "plt.xlabel('Scenario')\n",
    "plt.ylabel('Average Steps Taken')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Control Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'rq2b_efficiency_cost.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualization for RQ2: Oscillation count as measure of \"unsureness\"\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.boxplot(\n",
    "    data=rq2_df,\n",
    "    x='scenario_id',\n",
    "    y='oscillation_count',\n",
    "    hue='control_type',\n",
    "    palette=['lightgrey', 'darkblue']\n",
    ")\n",
    "\n",
    "plt.title('Agent \"Unsureness\": Oscillation Counts in Conflict-Avoidable Scenarios', fontsize=14)\n",
    "plt.xlabel('Scenario')\n",
    "plt.ylabel('Oscillation Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Control Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'rq2_unsureness.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3: Model Variation in Principle Adherence\n",
    "\n",
    "**Research Question**: Do different LLMs behave differently?\n",
    "\n",
    "This analysis examines how different models vary in their adherence to principles, especially in challenging conflict scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Model Comparison on Principle Adherence in High-Conflict Scenarios\n",
    "\n",
    "# Filter for Principle_ON and specifically selected unavoidable scenarios\n",
    "high_conflict_df = df[\n",
    "    (df['control_type'] == 'Principle_ON') & \n",
    "    (df['scenario_id'].isin(RQ3_SCENARIOS))\n",
    "]\n",
    "\n",
    "# Group by model and principle\n",
    "model_principle_df = high_conflict_df.groupby(['model', 'principle_id'])['principle_adhered'].mean().reset_index()\n",
    "\n",
    "# Create a grouped bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.barplot(\n",
    "    data=model_principle_df,\n",
    "    x='model',\n",
    "    y='principle_adhered',\n",
    "    hue='principle_id',\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "plt.title('Comparative Principle Adherence Across LLM Agents in High-Conflict Scenarios', fontsize=14)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Principle Adherence Rate (PAR)')\n",
    "format_percent_axis(ax)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Principle')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'rq3_model_comparison.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance scatter plot: Adherence vs Success\n",
    "\n",
    "# Filter for Principle_ON condition\n",
    "principle_on_df = df[df['control_type'] == 'Principle_ON'].copy()\n",
    "\n",
    "# Calculate average adherence and success for each model\n",
    "model_performance = principle_on_df.groupby('model').agg({\n",
    "    'principle_adhered': 'mean',\n",
    "    'task_success': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.scatterplot(\n",
    "    data=model_performance,\n",
    "    x='principle_adhered',\n",
    "    y='task_success',\n",
    "    s=150,  # Point size\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Add model labels to points\n",
    "for i, row in model_performance.iterrows():\n",
    "    plt.text(\n",
    "        row['principle_adhered'] + 0.01, \n",
    "        row['task_success'], \n",
    "        row['model'].split('/')[-1],  # Just the model name without path\n",
    "        fontsize=9\n",
    "    )\n",
    "\n",
    "# Add quadrant lines at 0.5 marks\n",
    "plt.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add quadrant labels\n",
    "plt.text(0.25, 0.75, \"High Success,\\nLow Adherence\", ha='center', fontsize=10)\n",
    "plt.text(0.75, 0.75, \"High Success,\\nHigh Adherence\", ha='center', fontsize=10)\n",
    "plt.text(0.25, 0.25, \"Low Success,\\nLow Adherence\", ha='center', fontsize=10)\n",
    "plt.text(0.75, 0.25, \"Low Success,\\nHigh Adherence\", ha='center', fontsize=10)\n",
    "\n",
    "plt.title('Model Performance: Principle Adherence vs. Task Success', fontsize=14)\n",
    "plt.xlabel('Principle Adherence Rate (PAR)')\n",
    "plt.ylabel('Task Success Rate (TSR)')\n",
    "format_percent_axis(ax)\n",
    "ax.set_xlim(0, 1)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'rq3_model_performance_scatter.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ4: Impact of Principle Type\n",
    "\n",
    "**Research Question**: How does the type of principle (movement, interaction, procedure) affect agent behavior?\n",
    "\n",
    "Here we examine how different types of principles present different challenges to LLM agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4: Impact of Principle Type on Adherence and Success\n",
    "\n",
    "# Group by principle and calculate overall metrics\n",
    "principle_summary = df.groupby(['principle_id', 'control_type']).agg({\n",
    "    'principle_adhered': 'mean',\n",
    "    'task_success': 'mean',\n",
    "    'steps_taken': 'mean',\n",
    "    'oscillation_count': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create a figure with multiple subplots using GridSpec\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "# Plot 1: Principle Adherence by Principle Type\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "sns.barplot(\n",
    "    data=principle_summary, \n",
    "    x='principle_id', \n",
    "    y='principle_adhered',\n",
    "    hue='control_type',\n",
    "    palette=['lightgrey', 'darkblue'],\n",
    "    ax=ax1\n",
    ")\n",
    "ax1.set_title('Principle Adherence by Principle Type')\n",
    "ax1.set_xlabel('Principle')\n",
    "ax1.set_ylabel('Principle Adherence Rate')\n",
    "format_percent_axis(ax1)\n",
    "ax1.legend(title='Control Type')\n",
    "\n",
    "# Plot 2: Task Success by Principle Type\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "sns.barplot(\n",
    "    data=principle_summary, \n",
    "    x='principle_id', \n",
    "    y='task_success',\n",
    "    hue='control_type',\n",
    "    palette=['lightgrey', 'darkblue'],\n",
    "    ax=ax2\n",
    ")\n",
    "ax2.set_title('Task Success by Principle Type')\n",
    "ax2.set_xlabel('Principle')\n",
    "ax2.set_ylabel('Task Success Rate')\n",
    "format_percent_axis(ax2)\n",
    "ax2.legend(title='Control Type')\n",
    "\n",
    "# Plot 3: Steps Taken by Principle Type\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "sns.barplot(\n",
    "    data=principle_summary, \n",
    "    x='principle_id', \n",
    "    y='steps_taken',\n",
    "    hue='control_type',\n",
    "    palette=['lightgrey', 'darkblue'],\n",
    "    ax=ax3\n",
    ")\n",
    "ax3.set_title('Steps Taken by Principle Type')\n",
    "ax3.set_xlabel('Principle')\n",
    "ax3.set_ylabel('Average Steps')\n",
    "ax3.legend(title='Control Type')\n",
    "\n",
    "# Plot 4: Oscillation Count by Principle Type\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "sns.barplot(\n",
    "    data=principle_summary, \n",
    "    x='principle_id', \n",
    "    y='oscillation_count',\n",
    "    hue='control_type',\n",
    "    palette=['lightgrey', 'darkblue'],\n",
    "    ax=ax4\n",
    ")\n",
    "ax4.set_title('Agent Oscillation by Principle Type')\n",
    "ax4.set_xlabel('Principle')\n",
    "ax4.set_ylabel('Average Oscillations')\n",
    "ax4.legend(title='Control Type')\n",
    "\n",
    "plt.suptitle('Impact of Principle Type on Agent Behavior', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.93)\n",
    "plt.savefig(os.path.join(output_dir, 'rq4_principle_type_impact.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Summary Table\n",
    "\n",
    "# Create a detailed summary table covering all principles, conflict types and control settings\n",
    "comprehensive_df = df.groupby(['principle_id', 'conflict_type', 'control_type']).agg({\n",
    "    'principle_adhered': ['mean', 'std'],\n",
    "    'task_success': ['mean', 'std'],\n",
    "    'steps_taken': ['mean', 'std'],\n",
    "    'oscillation_count': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the multi-index\n",
    "comprehensive_df.columns = ['_'.join(col).strip('_') for col in comprehensive_df.columns.values]\n",
    "\n",
    "# Format the numeric columns to show percentages with 2 decimal places\n",
    "for col in comprehensive_df.columns:\n",
    "    if col.endswith('mean') and ('principle_adhered' in col or 'task_success' in col):\n",
    "        comprehensive_df[col] = comprehensive_df[col].map(lambda x: f\"{x:.2%}\")\n",
    "    elif col.endswith('mean'):\n",
    "        comprehensive_df[col] = comprehensive_df[col].map(lambda x: f\"{x:.2f}\")\n",
    "    elif col.endswith('std') and ('principle_adhered' in col or 'task_success' in col):\n",
    "        comprehensive_df[col] = comprehensive_df[col].map(lambda x: f\"±{x:.2%}\")\n",
    "    elif col.endswith('std'):\n",
    "        comprehensive_df[col] = comprehensive_df[col].map(lambda x: f\"±{x:.2f}\")\n",
    "\n",
    "# Rename columns to be more readable\n",
    "readable_columns = {\n",
    "    'principle_id_': 'Principle',\n",
    "    'conflict_type_': 'Conflict Type',\n",
    "    'control_type_': 'Control Type',\n",
    "    'principle_adhered_mean': 'PAR',\n",
    "    'principle_adhered_std': 'PAR SD',\n",
    "    'task_success_mean': 'TSR',\n",
    "    'task_success_std': 'TSR SD',\n",
    "    'steps_taken_mean': 'Steps',\n",
    "    'steps_taken_std': 'Steps SD',\n",
    "    'oscillation_count_mean': 'Osc',\n",
    "    'oscillation_count_std': 'Osc SD'\n",
    "}\n",
    "\n",
    "comprehensive_df = comprehensive_df.rename(columns=readable_columns)\n",
    "\n",
    "# Display the table\n",
    "comprehensive_df.style.set_properties(**{'text-align': 'center'})\n",
    "\n",
    "# Save the table to CSV\n",
    "comprehensive_df.to_csv(os.path.join(output_dir, 'comprehensive_summary.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This analysis has demonstrated:\n",
    "\n",
    "1. **Principle Influence**: The activation of core principles significantly alters agent behavior, especially in unavoidable conflict scenarios.\n",
    "\n",
    "2. **Solution Finding**: In avoidable conflict scenarios, agents show varying abilities to find compliant paths, often with efficiency costs.\n",
    "\n",
    "3. **Model Variation**: Different LLM models exhibit distinct patterns in how they balance principle adherence with task completion.\n",
    "\n",
    "4. **Principle Type Impact**: The nature of the principle (movement restriction, interaction constraint, or procedural rule) influences how agents respond to conflicts.\n",
    "\n",
    "These findings have important implications for the design of AI systems that must balance task completion with safety constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sitewiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
